import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.utils import make_grid, save_image
from torchvision import transforms as T
from PIL import Image
import numpy as np
from sklearn.metrics import roc_auc_score
from torch.utils.tensorboard import SummaryWriter
import random  # äº‚æ•¸æ§åˆ¶
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score
from loss import FocalLoss, SSIM
from model_unet import AnomalyDetectionModel
from data_loader import MVTecDRAEMTrainDataset
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from datetime import datetime


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# =======================
# Utilities
# =======================
def get_available_gpu():
    """è‡ªå‹•é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨ç‡æœ€ä½çš„GPU"""
    if not torch.cuda.is_available():
        return -1  # æ²’æœ‰GPUå¯ç”¨

    gpu_count = torch.cuda.device_count()
    if gpu_count == 0:
        return -1

    # æª¢æŸ¥æ¯å€‹GPUçš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
    gpu_memory = []
    for i in range(gpu_count):
        torch.cuda.set_device(i)
        memory_allocated = torch.cuda.memory_allocated(i)
        memory_reserved = torch.cuda.memory_reserved(i)
        gpu_memory.append((i, memory_allocated, memory_reserved))

    # é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨æœ€å°‘çš„GPU
    available_gpu = min(gpu_memory, key=lambda x: x[1])[0]
    return available_gpu


def weights_init(m):
    """ å·ç©å±¤æ¬Šé‡ â†’ å°äº‚æ•¸è®“ç¶²è·¯å®¹æ˜“å­¸ç¿’ã€æ¢¯åº¦ç©©å®š
        BatchNormæ¬Šé‡ â†’ åˆå§‹ç¸®æ”¾ 1 ä¿æŒæ•¸å€¼ç©©å®šï¼Œåç½® 0 ä¸æ”¹è®Šå‡å€¼"""
    # å–å¾—æ¨¡çµ„çš„é¡åˆ¥åç¨±ï¼Œä¾‹å¦‚ 'Conv2d', 'BatchNorm2d' ç­‰
    classname = m.__class__.__name__

    # å¦‚æœæ˜¯å·ç©å±¤ (Conv)
    if classname.find('Conv') != -1:
        # æ¬Šé‡åˆå§‹åŒ–ç‚ºå‡å€¼ 0ã€æ¨™æº–å·® 0.02 çš„é«˜æ–¯åˆ†å¸ƒ
        # åŸå› ï¼šé€™æ¨£å¯ä»¥è®“å·ç©å±¤ä¸€é–‹å§‹è¼¸å‡ºçš„ç‰¹å¾µå€¼åˆ†å¸ƒå‡è¡¡ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸
        m.weight.data.normal_(0.0, 0.02)

    # å¦‚æœæ˜¯æ‰¹æ¬¡æ­£è¦åŒ–å±¤ (BatchNorm)
    elif classname.find('BatchNorm') != -1:
        # æ¬Šé‡åˆå§‹åŒ–ç‚ºå‡å€¼ 1ã€æ¨™æº–å·® 0.02 çš„é«˜æ–¯åˆ†å¸ƒ
        # åŸå› ï¼šBatchNorm çš„æ¬Šé‡ (gamma) æ§åˆ¶è¼¸å‡ºç¸®æ”¾ï¼Œåˆå§‹åŒ–ç‚º 1 å¯ä»¥ä¿æŒåˆå§‹ç‰¹å¾µåˆ†å¸ƒä¸è®Š
        m.weight.data.normal_(1.0, 0.02)
        # åç½®åˆå§‹åŒ–ç‚º 0
        # åŸå› ï¼šåç½® (beta) æ§åˆ¶è¼¸å‡ºåç§»é‡ï¼Œåˆå§‹åŒ–ç‚º 0 å¯ä»¥ä¿æŒè¼¸å‡ºå‡å€¼ä¸åç§»
        m.bias.data.fill_(0)


def visualize_predictions(teacher_model, student_model, batch, device,
                          save_path):
    """
    è¦–è¦ºåŒ–æ•™å¸«æ¨¡å‹å’Œå­¸ç”Ÿæ¨¡å‹çš„é æ¸¬çµæœå°æ¯”
    """
    teacher_model.eval()
    student_model.eval()
    with torch.no_grad():
        input_image = batch["image"].to(device)
        aug_image = batch["augmented_image"].to(device)
        gt_mask = batch["anomaly_mask"].to(device)

        # æ•™å¸«é æ¸¬
        teacher_recon, teacher_seg = teacher_model(aug_image)
        # å­¸ç”Ÿé æ¸¬
        student_recon, student_seg = student_model(aug_image)

        # è½‰æ›ç‚º numpy ç”¨æ–¼ç¹ªåœ–
        input_np = input_image.cpu().numpy()[0].transpose(1, 2, 0)
        aug_np = aug_image.cpu().numpy()[0].transpose(1, 2, 0)
        gt_mask_np = gt_mask.cpu().numpy()[0, 0]  # å–ç¬¬ä¸€å€‹é€šé“

        # è™•ç†åˆ†å‰²çµæœ
        teacher_seg_np = torch.softmax(teacher_seg,
                                       dim=1)[0, 1].cpu().numpy()  # ç•°å¸¸é¡åˆ¥æ¦‚ç‡
        student_seg_np = torch.softmax(student_seg, dim=1)[0, 1].cpu().numpy()

        # å‰µå»ºåœ–åƒ
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))

        # ç¬¬ä¸€è¡Œï¼šåŸå§‹è¼¸å…¥èˆ‡æ¨™è¨»
        axes[0, 0].imshow(input_np)  # åŸå§‹è¼¸å…¥å½±åƒï¼Œç”¨æ–¼åƒè€ƒçœŸå¯¦å ´æ™¯
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        axes[0, 1].imshow(aug_np)  # å¢å¼·å¾Œå½±åƒï¼Œå¯¦éš›è¼¸å…¥æ¨¡å‹çš„è³‡æ–™
        axes[0, 1].set_title('Augmented Image')
        axes[0, 1].axis('off')
        axes[0, 2].imshow(gt_mask_np, cmap='jet')  # Ground Truth ç•°å¸¸é®ç½©ï¼Œä½œç‚ºæ¨™æº–ç­”æ¡ˆ
        axes[0, 2].set_title('Ground Truth Mask')
        axes[0, 2].axis('off')
        axes[0, 3].axis('off')  # ç©ºç™½

        # ç¬¬äºŒè¡Œï¼šæ¨¡å‹é æ¸¬èˆ‡æ¯”è¼ƒ
        im1 = axes[1, 0].imshow(teacher_seg_np, cmap='jet', vmin=0,
                                vmax=1)  # æ•™å¸«æ¨¡å‹çš„ç•°å¸¸æ©Ÿç‡åˆ†ä½ˆï¼Œä½œç‚ºå­¸ç”Ÿæ¨¡å‹çš„å­¸ç¿’ç›®æ¨™
        axes[1, 0].set_title('Teacher Segmentation')
        axes[1, 0].axis('off')
        plt.colorbar(im1, ax=axes[1, 0])

        im2 = axes[1, 1].imshow(student_seg_np, cmap='jet', vmin=0,
                                vmax=1)  # å­¸ç”Ÿæ¨¡å‹çš„ç•°å¸¸æ©Ÿç‡åˆ†ä½ˆï¼Œç”¨æ–¼èˆ‡æ•™å¸«æ¨¡å‹åšå°æ¯”
        axes[1, 1].set_title('Student Segmentation')
        axes[1, 1].axis('off')
        plt.colorbar(im2, ax=axes[1, 1])
        # å·®ç•°åœ–
        diff = np.abs(teacher_seg_np - student_seg_np)
        im3 = axes[1, 2].imshow(diff, cmap='hot', vmin=0,
                                vmax=1)  # æ•™å¸«èˆ‡å­¸ç”Ÿæ¨¡å‹é æ¸¬å·®ç•°åœ–ï¼Œé¡¯ç¤ºå…©è€…åœ¨ç©ºé–“ä¸Šçš„é æ¸¬åå·®
        axes[1, 2].set_title('Teacher-Student Difference')
        axes[1, 2].axis('off')
        plt.colorbar(im3, ax=axes[1, 2])
        # äºŒå€¼åŒ–å°æ¯”
        student_binary = (student_seg_np > 0.5).astype(np.float32)
        im4 = axes[1, 3].imshow(student_binary,
                                cmap='gray')  # å­¸ç”Ÿæ¨¡å‹çš„äºŒå€¼åŒ–çµæœï¼ˆé–¾å€¼0.5ï¼‰ï¼Œç”¨æ–¼è§€å¯Ÿæœ€çµ‚ç•°å¸¸åˆ¤æ–·å€åŸŸ
        axes[1, 3].set_title('Student Binary (>0.5)')
        axes[1, 3].axis('off')

        plt.tight_layout()
        plt.savefig(save_path + '.png', dpi=150, bbox_inches='tight')
        plt.close()
        student_model.train()
        print(f"âœ… Visualization saved: {save_path}.png")


def detailed_diagnostic_visualization(teacher_model, student_model, loss_focal,
                                      batch, device, save_path, epoch,
                                      i_batch):
    """
    æ›´è©³ç´°çš„è¨ºæ–·è¦–è¦ºåŒ–ï¼ŒåŒ…å«æå¤±å€¼å’ŒæŒ‡æ¨™
    """
    teacher_model.eval()
    student_model.eval()
    with torch.no_grad():
        input_image = batch["image"].to(device)
        aug_image = batch["augmented_image"].to(device)
        gt_mask = batch["anomaly_mask"].to(device)

        # ç²å–é æ¸¬
        teacher_recon, teacher_seg = teacher_model(aug_image)
        student_recon, student_seg = student_model(aug_image)

        # è¨ˆç®—ç•¶å‰æå¤±ï¼ˆåƒ…ç”¨æ–¼é¡¯ç¤ºï¼‰
        seg_distill_loss = F.mse_loss(student_seg, teacher_seg).item()
        student_seg_softmax = torch.softmax(student_seg, dim=1)
        orig_seg_loss = loss_focal(student_seg_softmax, gt_mask).item()

        # è½‰æ›ç‚º numpy
        input_np = input_image.cpu().numpy()[0].transpose(1, 2, 0)
        aug_np = aug_image.cpu().numpy()[0].transpose(1, 2, 0)
        gt_mask_np = gt_mask.cpu().numpy()[0, 0]
        teacher_seg_np = torch.softmax(teacher_seg, dim=1)[0, 1].cpu().numpy()
        student_seg_np = torch.softmax(student_seg, dim=1)[0, 1].cpu().numpy()

        # å‰µå»ºè¨ºæ–·åœ–
        fig, axes = plt.subplots(2, 5, figsize=(25, 10))

        # ç¬¬ä¸€è¡Œï¼šè¼¸å…¥èˆ‡é æ¸¬
        axes[0, 0].imshow(input_np)  # åŸå§‹å½±åƒ
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        axes[0, 1].imshow(aug_np)  # å¢å¼·å½±åƒ
        axes[0, 1].set_title('Augmented Image')
        axes[0, 1].axis('off')
        axes[0, 2].imshow(gt_mask_np, cmap='jet')  # Ground Truth ç•°å¸¸é®ç½©
        axes[0, 2].set_title('GT Mask')
        axes[0, 2].axis('off')

        axes[0, 3].imshow(teacher_seg_np, cmap='jet', vmin=0,
                          vmax=1)  # æ•™å¸«æ¨¡å‹é æ¸¬ï¼Œä¸¦é¡¯ç¤ºæœ€å¤§ç•°å¸¸æ©Ÿç‡å€¼ï¼Œè©•ä¼°å…¶æ•æ„Ÿåº¦
        axes[0, 3].set_title(f'Teacher Seg\nMax: {teacher_seg_np.max():.3f}')
        axes[0, 3].axis('off')
        axes[0, 4].imshow(student_seg_np, cmap='jet', vmin=0, vmax=1)
        axes[0, 4].set_title(f'Student Seg\nMax: {student_seg_np.max():.3f}')
        axes[0, 4].axis('off')  # å­¸ç”Ÿæ¨¡å‹é æ¸¬ï¼Œä¸¦é¡¯ç¤ºæœ€å¤§ç•°å¸¸æ©Ÿç‡å€¼ï¼Œè©•ä¼°å…¶åµæ¸¬èƒ½åŠ›

        # ç¬¬äºŒè¡Œï¼šåˆ†æå’Œå·®ç•°
        diff = np.abs(teacher_seg_np - student_seg_np)
        axes[1, 0].imshow(diff, cmap='hot')  # æ•™å¸«èˆ‡å­¸ç”Ÿçš„å·®ç•°åœ–ï¼Œä¸¦é¡¯ç¤ºå¹³å‡å·®ç•°å€¼ï¼Œç”¨æ–¼è¡¡é‡çŸ¥è­˜è’¸é¤¾æ•ˆæœ
        axes[1, 0].set_title(f'Difference\nAvg: {diff.mean():.3f}')
        axes[1, 0].axis('off')
        # å­¸ç”ŸäºŒå€¼åŒ–
        student_binary = (student_seg_np > 0.5).astype(np.float32)
        axes[1, 1].imshow(student_binary,
                          cmap='gray')  # å­¸ç”Ÿæ¨¡å‹çš„äºŒå€¼åŒ–çµæœï¼Œè§€å¯Ÿå…¶æœ€çµ‚ç•°å¸¸åˆ¤æ–·å€åŸŸ
        axes[1, 1].set_title('Student Binary\n(>0.5)')
        axes[1, 1].axis('off')
        # æ•™å¸«äºŒå€¼åŒ–
        teacher_binary = (teacher_seg_np > 0.5).astype(np.float32)
        axes[1, 2].imshow(teacher_binary,
                          cmap='gray')  # æ•™å¸«æ¨¡å‹çš„äºŒå€¼åŒ–çµæœï¼Œä½œç‚ºå­¸ç”Ÿæ¨¡å‹çš„åƒè€ƒæ¨™æº–
        axes[1, 2].set_title('Teacher Binary\n(>0.5)')
        axes[1, 2].axis('off')

        # æå¤±ä¿¡æ¯
        # é¡¯ç¤ºç›®å‰è¨“ç·´é€±æœŸèˆ‡æ‰¹æ¬¡ç·¨è™Ÿï¼Œä»¥åŠå…©ç¨®æå¤±å€¼ï¼š
        # - seg_distill_lossï¼šå­¸ç”Ÿæ¨¡ä»¿æ•™å¸«çš„æå¤±
        # - orig_seg_lossï¼šå­¸ç”Ÿå° Ground Truth çš„é æ¸¬æå¤±
        axes[1, 3].text(0.1,
                        0.7, f'Epoch: {epoch}\nBatch: {i_batch}\n\n'
                        f'Seg Distill Loss: {seg_distill_loss:.4f}\n'
                        f'Orig Seg Loss: {orig_seg_loss:.4f}',
                        fontsize=12)
        axes[1, 3].axis('off')

        # çµ±è¨ˆä¿¡æ¯
        # é¡¯ç¤ºæ•™å¸«èˆ‡å­¸ç”Ÿæ¨¡å‹çš„çµ±è¨ˆè³‡è¨Šï¼ˆå¹³å‡å€¼èˆ‡æ¨™æº–å·®ï¼‰ï¼Œ
        # ç”¨æ–¼åˆ†ææ¨¡å‹é æ¸¬çš„ç©©å®šæ€§èˆ‡åˆ†ä½ˆç‰¹æ€§ï¼š
        # - Meanï¼šä»£è¡¨æ•´é«”ç•°å¸¸æ©Ÿç‡çš„å¹³å‡å¼·åº¦
        # - Stdï¼šä»£è¡¨é æ¸¬åˆ†ä½ˆçš„é›¢æ•£ç¨‹åº¦ï¼Œè¶Šé«˜è¡¨ç¤ºæ¨¡å‹é æ¸¬è¶Šä¸ç©©å®š
        axes[1, 4].text(0.1,
                        0.7, f'Teacher Stats:\n'
                        f'Mean: {teacher_seg_np.mean():.3f}\n'
                        f'Std: {teacher_seg_np.std():.3f}\n\n'
                        f'Student Stats:\n'
                        f'Mean: {student_seg_np.mean():.3f}\n'
                        f'Std: {student_seg_np.std():.3f}',
                        fontsize=12)
        axes[1, 4].axis('off')

        plt.tight_layout()
        plt.savefig(save_path + '_diagnostic.png',
                    dpi=150,
                    bbox_inches='tight')
        plt.close()
        student_model.train()
        print(f"âœ… Diagnostic visualization saved: {save_path}_diagnostic.png")


# =======================
# Main Pipeline
# =======================
def main(obj_names, args):
    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    device = "cuda" if torch.cuda.is_available() else "cpu"
    for obj_name in obj_names:
        # Load teacher
        recon_path = f'./DRAEM_checkpoints/DRAEM_seg_large_ae_large_0.0001_800_bs8_' + obj_name + '_'
        checkpoint_path = recon_path + ".pckl"
        teacher_recon_ckpt = torch.load(checkpoint_path,
                                        map_location=device,
                                        weights_only=True)
        print("teacher_recon_ckpt keys:", teacher_recon_ckpt.keys())

        seg_path = f'./DRAEM_checkpoints/DRAEM_seg_large_ae_large_0.0001_800_bs8_' + obj_name + '__seg'
        checkpoint_seg_path = seg_path + ".pckl"
        teacher_seg_ckpt = torch.load(checkpoint_seg_path,
                                      map_location=device,
                                      weights_only=True)
        print("teacher_seg_ckpt keys:", teacher_seg_ckpt.keys())
        # # åˆä½µå…©å€‹ state_dict
        # full_ckpt = {}
        # full_ckpt.update(teacher_recon_ckpt)  # encoder/decoder æ¬Šé‡
        # full_ckpt.update(teacher_seg_ckpt)  # discriminator æ¬Šé‡

        # å‰µå»ºä¸€å€‹æ–°çš„ state_dict ä¾†å­˜æ”¾ä¿®æ­£å¾Œçš„éµ
        new_teacher_state_dict = {}

        # ç‚ºé‡å»ºå­ç¶²è·¯çš„æ¬Šé‡åŠ ä¸Š "reconstruction_subnet." å‰ç¶´
        for key, value in teacher_recon_ckpt.items():
            new_key = "reconstruction_subnet." + key
            new_teacher_state_dict[new_key] = value

        # ç‚ºåˆ¤åˆ¥å­ç¶²è·¯çš„æ¬Šé‡åŠ ä¸Š "discriminator_subnet." å‰ç¶´
        for key, value in teacher_seg_ckpt.items():
            # åŸå§‹çš„DRAEM checkpointå¯èƒ½åŒ…å« "module." å‰ç¶´ï¼ˆå¦‚æœä½¿ç”¨äº†DataParallelï¼‰
            if key.startswith('module.'):
                key = key[7:]
            new_key = "discriminator_subnet." + key
            new_teacher_state_dict[new_key] = value

        # å‡è¨­æ˜¯è™•ç†3é€šé“çš„RGBåœ–åƒ
        IMG_CHANNELS = 3
        # åˆ†å‰²ä»»å‹™æ˜¯äºŒåˆ†é¡ (ç•°å¸¸ vs. æ­£å¸¸)
        SEG_CLASSES = 2
        # å»ºç«‹æ•™å¸«æ¨¡å‹çš„çµæ§‹ï¼Œè¼¸å…¥èˆ‡è¼¸å‡ºé€šé“çš†ç‚º 3ï¼ˆRGBï¼‰ï¼Œä¸¦ç§»å‹•åˆ°æŒ‡å®šè£ç½®ä¸Š
        teacher_model = AnomalyDetectionModel(
            recon_in=IMG_CHANNELS,
            recon_out=IMG_CHANNELS,
            recon_base=128,  # æ•™å¸«é‡å»ºç¶²è·¯è¼ƒå¯¬
            disc_in=IMG_CHANNELS * 2,  # åŸåœ–+é‡å»ºåœ–
            disc_out=SEG_CLASSES,
            disc_base=64  # æ•™å¸«åˆ¤åˆ¥ç¶²è·¯è¼ƒå¯¬
        ).to(device)
        # # æª¢æŸ¥ checkpoint çµæ§‹
        # print("Checkpoint keys:", full_ckpt.keys())

        print("Checkpoint keys:", new_teacher_state_dict.keys())
        # ç¾åœ¨ä½¿ç”¨ä¿®æ­£å¾Œçš„ state_dict è¼‰å…¥ï¼Œä¸¦ä½¿ç”¨ strict=True ä¾†ç¢ºä¿æ‰€æœ‰æ¬Šé‡éƒ½æ­£ç¢ºè¼‰å…¥
        teacher_model.load_state_dict(new_teacher_state_dict, strict=True)

        # # å°‡æ•™å¸«æ¨¡å‹çš„åƒæ•¸è¼‰å…¥è‡³æ¨¡å‹ä¸­ï¼Œä½¿ç”¨ checkpoint ä¸­çš„ 'reconstructive' æ¬„ä½
        # teacher_model.load_state_dict(full_ckpt, strict=False)
        # å°‡æ•™å¸«æ¨¡å‹è¨­ç‚ºè©•ä¼°æ¨¡å¼ï¼Œåœç”¨ Dropoutã€BatchNorm ç­‰è¨“ç·´å°ˆç”¨æ©Ÿåˆ¶
        teacher_model.eval()

        # å°‡æ•™å¸«æ¨¡å‹çš„æ‰€æœ‰åƒæ•¸è¨­ç‚ºä¸å¯è¨“ç·´ï¼Œé¿å…åœ¨å¾ŒçºŒè¨“ç·´ä¸­è¢«æ›´æ–°
        for p in teacher_model.parameters():
            p.requires_grad = False

        # Student model
        #dropout é˜²æ­¢éæ“¬åˆï¼Œå¹«åŠ©å­¸ç”Ÿæ¨¡å‹æ³›åŒ–ï¼Œé¿å…éæ“¬åˆæ•™å¸«æ¨¡å‹æå–çš„ç‰¹å¾µã€‚åœ¨è’¸é¤¾è¨“ç·´æ™‚ï¼Œè®“å­¸ç”Ÿæ¨¡å‹å­¸åˆ°æ›´ç©©å¥çš„ç‰¹å¾µï¼Œè€Œä¸æ˜¯å®Œå…¨æ¨¡ä»¿æ•™å¸«æ¨¡å‹çš„å–®ä¸€è·¯å¾‘
        student_model = AnomalyDetectionModel(
            recon_in=IMG_CHANNELS,
            recon_out=IMG_CHANNELS,
            recon_base=64,  # å­¸ç”Ÿé‡å»ºç¶²è·¯è¼ƒçª„
            disc_in=IMG_CHANNELS * 2,  # åŸåœ–+é‡å»ºåœ–
            disc_out=SEG_CLASSES,
            disc_base=64  # å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯è¼ƒçª„
        ).to(device)

        #åˆå§‹åŒ– å·ç©å±¤å’Œ BatchNorm å±¤çš„åˆå§‹æ¬Šé‡åˆ†å¸ƒåˆç†ï¼Œå¹«åŠ©æ¨¡å‹æ›´å¿«æ”¶æ–‚
        student_model.apply(weights_init)

        # --- ç‰¹å¾µå°é½Šå±¤ ---
        # åˆ¤åˆ¥ç¶²è·¯çš„ç‰¹å¾µç¶­åº¦ä¸åŒï¼Œéœ€è¦å°é½Šå±¤ä¾†è¨ˆç®—è’¸é¤¾æå¤±
        # å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯çš„é€šé“æ•¸
        s_channels = [64, 128, 256, 512, 512, 512]
        # æ•™å¸«åˆ¤åˆ¥ç¶²è·¯çš„é€šé“æ•¸
        t_channels = [64, 128, 256, 512, 512, 512]
        # ä½¿ç”¨ ModuleList å»ºç«‹å¤šå€‹ 1x1 Conv2d å±¤ï¼Œç”¨ä¾†å°‡å­¸ç”Ÿç‰¹å¾µå°é½Šåˆ°æ•™å¸«ç‰¹å¾µ
        feature_aligns = nn.ModuleList([
            nn.Conv2d(s_c, t_c, kernel_size=1, bias=False)
            for s_c, t_c in zip(s_channels, t_channels)
        ]).to(device)

        # å®šç¾©å„ªåŒ–å™¨ï¼Œåªå„ªåŒ–å­¸ç”Ÿæ¨¡å‹å’Œç‰¹å¾µå°é½Šå±¤çš„åƒæ•¸
        optimizer = torch.optim.Adam(list(student_model.parameters()) +
                                     list(feature_aligns.parameters()),
                                     lr=args.lr)
        # è¨­å®šå­¸ç¿’ç‡èª¿æ•´ç­–ç•¥ï¼Œä½¿ç”¨ MultiStepLR(ä¸€é–‹å§‹å¤§æ­¥èµ°ï¼Œå¾Œé¢å°æ­¥èµ°)
        scheduler = optim.lr_scheduler.MultiStepLR(
            optimizer,  # éœ€è¦èª¿æ•´çš„å„ªåŒ–å™¨
            [args.epochs * 0.8, args.epochs * 0.9],  # åœ¨è¨“ç·´ 80% å’Œ 90% æ™‚èª¿æ•´å­¸ç¿’ç‡
            gamma=0.2,  # æ¯æ¬¡èª¿æ•´æ™‚å­¸ç¿’ç‡ä¹˜ä¸Š 0.2
            last_epoch=-1)  # å¾é ­é–‹å§‹è¨ˆç®—å­¸ç¿’ç‡
        # å®šç¾©æå¤±å‡½æ•¸
        loss_focal = FocalLoss()  #è§£æ±ºé¡åˆ¥ä¸å¹³è¡¡ã€å¼·åŒ–æ¨¡å‹å°é›£åˆ†é¡æ¨£æœ¬çš„å­¸ç¿’ã€‚

        path = f'./mvtec'  # è¨“ç·´è³‡æ–™è·¯å¾‘
        path_dtd = f'./dtd/images/'
        # Load datasets
        # è¼‰å…¥è¨“ç·´è³‡æ–™é›†ï¼ŒæŒ‡å®šæ ¹ç›®éŒ„ã€é¡åˆ¥ã€è³‡æ–™åˆ‡åˆ†æ–¹å¼ç‚º "train"ï¼Œä¸¦å°‡å½±åƒå°ºå¯¸èª¿æ•´ç‚º 256x256
        #python train_DRAEM.py --gpu_id 0 --obj_id -1 --lr 0.0001 --bs 8 --epochs 700 --data_path ./datasets/mvtec/ --anomaly_source_path ./datasets/dtd/images/ --checkpoint_path ./checkpoints/ --log_path ./logs/

        train_dataset = MVTecDRAEMTrainDataset(root_dir=path +
                                               f'/{obj_name}/train/good/',
                                               anomaly_source_path=path_dtd,
                                               resize_shape=[256, 256])
        # å»ºç«‹è¨“ç·´è³‡æ–™çš„ DataLoaderï¼Œè¨­å®šæ¯æ‰¹æ¬¡å¤§å°ç‚º 16ï¼Œæ‰“äº‚è³‡æ–™é †åºï¼Œä½¿ç”¨ 4 å€‹åŸ·è¡Œç·’åŠ é€Ÿè¼‰å…¥
        train_loader = DataLoader(train_dataset,
                                  batch_size=args.bs,
                                  shuffle=True,
                                  num_workers=4)
        # ä¸»å„²å­˜è³‡æ–™å¤¾è·¯å¾‘
        save_root = "./save_files"

        # è‹¥ä¸»è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œå‰‡å»ºç«‹
        if not os.path.exists(save_root):
            os.makedirs(save_root)

        # TensorBoard
        # å»ºç«‹ TensorBoard çš„ç´€éŒ„å™¨ï¼Œå°‡è¨“ç·´éç¨‹çš„æŒ‡æ¨™èˆ‡åœ–åƒè¼¸å‡ºåˆ°æŒ‡å®šç›®éŒ„ "./save_files"
        writer = SummaryWriter(log_dir=save_root)
        # æŒ‡å®šæ¨¡å‹æª¢æŸ¥é»ï¼ˆcheckpointï¼‰å„²å­˜çš„è³‡æ–™å¤¾è·¯å¾‘
        # æ¨¡å‹æª¢æŸ¥é»å„²å­˜è·¯å¾‘
        checkpoint_dir = os.path.join(save_root, "checkpoints")
        # å¦‚æœæª¢æŸ¥é»è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œå‰‡å»ºç«‹è©²è³‡æ–™å¤¾ï¼ˆexist_ok=True è¡¨ç¤ºè‹¥å·²å­˜åœ¨å‰‡ä¸å ±éŒ¯ï¼‰
        os.makedirs(checkpoint_dir, exist_ok=True)

        # é–‹å§‹é€²è¡Œå¤šè¼ªè¨“ç·´è¿´åœˆ
        n_iter = 0

        # --- è¶…åƒæ•¸å®šç¾© ---
        # å°‡åŸå§‹åˆ†å‰²æå¤±çš„æ¬Šé‡æå‡ç‚ºä¸»è¦ä¿¡è™Ÿæº
        lambda_orig_seg = 10.0

        # ä¿æŒé‡å»ºæå¤±ä½œç‚ºä¸€å€‹é‡è¦çš„åŸºç·š
        lambda_recon = 1.5

        # é©ç•¶é™ä½åˆ†å‰²è’¸é¤¾çš„æ¬Šé‡ï¼Œè®“å®ƒèˆ‡åŸå§‹åˆ†å‰²è™•æ–¼åŒç­‰æˆ–ç¨ä½çš„åœ°ä½
        lambda_seg_distill = 2.0  # æˆ–è€…æ‚¨ä¹Ÿå¯ä»¥å¾ 1.0 é–‹å§‹

        # ç‰¹å¾µè’¸é¤¾ä½œç‚ºè¼”åŠ©é …ï¼Œä¿æŒè¼ƒä½æ¬Šé‡
        lambda_feat_distill = 1.0

        best_loss = float("inf")
        # åœ¨è¨“ç·´é–‹å§‹å‰åˆå§‹åŒ– best_seg_distill_loss
        best_seg_distill_loss = float('inf')  # åˆå§‹åŒ–ç‚ºä¸€å€‹å¾ˆå¤§çš„æ•¸å€¼
        # åœ¨è¨“ç·´é–‹å§‹å‰åˆå§‹åŒ– best_orig_seg_loss
        best_orig_seg_loss = float('inf')  # åˆå§‹åŒ–ç‚ºä¸€å€‹å¾ˆå¤§çš„æ•¸å€¼

        for epoch in range(args.epochs):
            print("Epoch: " + str(epoch))

            epoch_loss = 0.0  # ç”¨ä¾†ç´¯åŠ ä¸€æ•´å€‹ epoch çš„ loss
            # åœ¨è¨“ç·´å¾ªç’°ä¸­ç´¯åŠ  seg_distill_loss
            epoch_seg_distill_loss = 0.0
            epoch_orig_seg_loss = 0.0

            num_batches = 0  # æ‰¹æ¬¡æ•¸é‡è¨ˆæ•¸å™¨
            for i_batch, sample_batched in enumerate(train_loader):
                # éæ­·è¨“ç·´è³‡æ–™é›†çš„æ¯å€‹æ‰¹æ¬¡
                input_image = sample_batched["image"].to(device)  # æ­£å¸¸åœ–åƒ
                ground_truth_mask = sample_batched["anomaly_mask"].to(
                    device)  # å°æ‡‰ aug_gray_batch çš„é®ç½©
                aug_gray_batch = sample_batched["augmented_image"].to(
                    device)  # å¸¶ç•°å¸¸çš„åœ–åƒ

                # --- æ•™å¸«ç¶²è·¯å‰å‘å‚³æ’­ (è¼¸å…¥å¸¶ç•°å¸¸çš„åœ–åƒ) ---
                with torch.no_grad():
                    # æ•™å¸«æ¨¡å‹å° aug_gray_batch é€²è¡Œåˆ¤æ–·ï¼Œä»¥æä¾›è’¸é¤¾ç›®æ¨™
                    _, teacher_seg_map, teacher_features = teacher_model(
                        aug_gray_batch, return_feats=True)

                # --- å­¸ç”Ÿç¶²è·¯å‰å‘å‚³æ’­ (è¼¸å…¥å¸¶ç•°å¸¸çš„åœ–åƒï¼Œç”¨æ–¼åˆ†å‰²) ---
                # å­¸ç”Ÿæ¨¡å‹å° aug_gray_batch é€²è¡Œåˆ¤æ–·
                _, student_seg_map, student_features = student_model(
                    aug_gray_batch, return_feats=True)

                # --- è¨ˆç®—æå¤±å‡½æ•¸ ---

                # 1. ç‰¹å¾µè’¸é¤¾æå¤±
                feat_distill_loss = 0.0
                for i in range(len(student_features)):
                    # å°‡å­¸ç”Ÿç‰¹å¾µå°é½Šåˆ°æ•™å¸«ç‰¹å¾µçš„ç¶­åº¦
                    aligned_student_feat = feature_aligns[i](
                        student_features[i])
                    feat_distill_loss += F.mse_loss(
                        F.normalize(aligned_student_feat, p=2, dim=1),
                        F.normalize(teacher_features[i], p=2, dim=1))

                # 2. åˆ†å‰²è’¸é¤¾æå¤± (Segmentation Distillation Loss)

                seg_distill_loss = F.mse_loss(student_seg_map, teacher_seg_map)

                # 3. åŸå§‹åˆ†å‰²æå¤± (Original Segmentation Loss)
                # ä½¿ç”¨çœŸå¯¦çš„ç•°å¸¸é®ç½©ç›£ç£å­¸ç”Ÿçš„åˆ†å‰²çµæœ
                # ä»¥ç„¦é»æå¤± (Focal Loss) ç‚ºä¾‹
                student_seg_softmax = torch.softmax(student_seg_map, dim=1)
                orig_seg_loss = loss_focal(student_seg_softmax,
                                           ground_truth_mask)

                # 4. æ–°å¢ï¼šé‡å»ºæå¤± (Reconstruction Loss)
                # é€™å€‹æå¤±åªåœ¨è¼¸å…¥æ˜¯ "æ­£å¸¸" åœ–åƒæ™‚è¨ˆç®—æ‰æœ‰æ„ç¾©ï¼Œ
                # ä½†åœ¨ DRAEM çš„è¨­å®šä¸­ï¼Œæˆ‘å€‘ç”¨ aug_gray_batchï¼Œå®ƒæ˜¯æœ‰ç•°å¸¸çš„ã€‚
                # æ­£ç¢ºçš„åšæ³•æ˜¯è®“é‡å»ºç¶²è·¯å»é‡å»ºåŸå§‹çš„ã€ç„¡ç•°å¸¸çš„åœ–åƒ input_image

                # è®“å­¸ç”Ÿæ¨¡å‹ä¹Ÿå°åŸå§‹æ­£å¸¸åœ–åƒé€²è¡Œé‡å»º
                student_recon_normal, _ = student_model(input_image,
                                                        return_feats=False)
                recon_loss = F.l1_loss(student_recon_normal, input_image)

                # --- é‡å»ºç¶²è·¯çš„å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯ç¸½æå¤± ---
                # --- ç¸½æå¤±èˆ‡æ›´æ–° ---
                total_loss = (lambda_recon * recon_loss +
                              lambda_feat_distill * feat_distill_loss +
                              lambda_seg_distill * seg_distill_loss +
                              lambda_orig_seg * orig_seg_loss)
                # ==================== è¨ºæ–·ç¨‹å¼ç¢¼ ====================
                if i_batch % 50 == 0:  # æ¯ 50 å€‹ batch å°ä¸€æ¬¡
                    print(f"\n[Epoch {epoch}, Batch {i_batch}] Loss values:")
                    print(
                        f"  - Recon Loss        : {recon_loss.item():.4f} (Weighted: {lambda_recon * recon_loss.item():.4f})"
                    )
                    print(
                        f"  - Feat Distill Loss : {feat_distill_loss.item():.4f} (Weighted: {lambda_feat_distill * feat_distill_loss.item():.4f})"
                    )
                    print(
                        f"  - Seg Distill Loss  : {seg_distill_loss.item():.4f} (Weighted: {lambda_seg_distill * seg_distill_loss.item():.4f})"
                    )
                    print(
                        f"  - Orig Seg Loss     : {orig_seg_loss.item():.4f} (Weighted: {lambda_orig_seg * orig_seg_loss.item():.4f})"
                    )
                    print(f"  - Total Loss        : {total_loss.item():.4f}")
                # --- åå‘å‚³æ’­èˆ‡åƒæ•¸æ›´æ–° ---
                # æ¸…é™¤å…ˆå‰è¨ˆç®—çš„æ¢¯åº¦
                optimizer.zero_grad()
                # è¨ˆç®—æ¢¯åº¦
                total_loss.backward()
                # æ›´æ–°å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯ (ä»¥åŠé‡å»ºç¶²è·¯) çš„æ¬Šé‡
                optimizer.step()

                # æ¯ N å€‹æ‰¹æ¬¡é€²è¡Œä¸€æ¬¡è¦–è¦ºåŒ–
                if i_batch % 100 == 0:  # æ¯100å€‹batchè¦–è¦ºåŒ–ä¸€æ¬¡
                    visualize_predictions(
                        teacher_model, student_model, sample_batched, device,
                        os.path.join(save_root,
                                     f"vis_epoch_{epoch}_batch_{i_batch}"))

                # æ¯500å€‹batché€²è¡Œè©³ç´°è¨ºæ–·
                if i_batch % 500 == 0:
                    detailed_diagnostic_visualization(
                        teacher_model, student_model, loss_focal,
                        sample_batched, device,
                        os.path.join(save_root,
                                     f"diag_epoch_{epoch}_batch_{i_batch}"),
                        epoch, i_batch)

                # ç´¯åŠ  epoch loss
                epoch_loss += total_loss.item()
                # ç´¯åŠ  seg_distill_loss
                epoch_seg_distill_loss += seg_distill_loss.item()
                # ç´¯åŠ  orig_seg_loss
                epoch_orig_seg_loss += orig_seg_loss.item()

                num_batches += 1

                # è¨˜éŒ„è¨“ç·´éç¨‹
                writer.add_scalar("Train/Total_Loss", total_loss.item(),
                                  n_iter)
                writer.add_scalar("Train/Feature_Distillation_Loss",
                                  feat_distill_loss.item(), n_iter)
                writer.add_scalar("Train/Segmentation_Distillation_Loss",
                                  seg_distill_loss.item(), n_iter)
                writer.add_scalar("Train/Original_Segmentation_Loss",
                                  orig_seg_loss.item(), n_iter)

                n_iter += 1

            # æ¯å€‹ epoch çµæŸå¾Œæ›´æ–°å­¸ç¿’ç‡ä¸¦ä¿å­˜æ¨¡å‹
            scheduler.step()
            # torch.save(student_model.state_dict(),
            #            os.path.join(checkpoint_dir, obj_name + ".pckl"))

            # å¦‚æœæ¯”æ­·å²æœ€ä½³é‚„ä½ï¼Œå°±ä¿å­˜ç‚º best
            # è¨ˆç®—å¹³å‡ loss
            # avg_loss = epoch_loss / num_batches
            # print(f"ğŸ“Š Epoch {epoch} Average Loss: {avg_loss:.4f}")
            # # åˆ¤æ–·æ˜¯å¦ä¿å­˜æœ€ä½³æ¨¡å‹
            # if avg_loss < best_loss:
            #     best_loss = avg_loss
            #     torch.save(student_model.state_dict(),
            #                os.path.join(checkpoint_dir, obj_name + ".pckl"))
            #     print(
            #         f"âœ… New best model saved at epoch {epoch}, avg_loss={avg_loss:.4f}"
            #     )

            #**åŸå§‹åˆ†å‰²æå¤±å…·æœ‰æœ€é«˜æ¬Šé‡(10.0)ï¼Œè¡¨æ˜å®ƒæ˜¯æœ€é‡è¦çš„è¨“ç·´æŒ‡æ¨™ï¼Œå…¶æ¬¡æ˜¯åˆ†å‰²è’¸é¤¾æå¤±(5.0)

            # # è¨ˆç®—å¹³å‡ Seg Distill Loss
            # avg_seg_distill_loss = epoch_seg_distill_loss / num_batches
            # print(
            #     f"ğŸ“Š Epoch {epoch} Average Seg Distill Loss: {avg_seg_distill_loss:.4f}"
            # )

            # # æ”¹ç”¨ Seg Distill Loss åˆ¤æ–·æœ€ä½³æ¨¡å‹
            # if avg_seg_distill_loss < best_seg_distill_loss:
            #     best_seg_distill_loss = avg_seg_distill_loss
            #     torch.save(student_model.state_dict(),
            #                os.path.join(checkpoint_dir, obj_name + ".pckl"))
            #     print(
            #         f"âœ… New best model saved at epoch {epoch}, seg_distill_loss={avg_seg_distill_loss:.4f}"
            #     )

            # è¨ˆç®—å¹³å‡ Orig Seg Loss
            avg_orig_seg_loss = epoch_orig_seg_loss / num_batches
            print(
                f"ğŸ“Š Epoch {epoch} Average Orig Seg Loss: {avg_orig_seg_loss:.4f}"
            )

            # åˆ¤æ–·æ˜¯å¦ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆæ”¹ç”¨ Orig Seg Lossï¼‰
            if avg_orig_seg_loss < best_orig_seg_loss:
                best_orig_seg_loss = avg_orig_seg_loss
                torch.save(student_model.state_dict(),
                           os.path.join(checkpoint_dir, obj_name + ".pckl"))
                print(
                    f"âœ… New best model saved at epoch {epoch}, orig_seg_loss={avg_orig_seg_loss:.4f}"
                )
        # é—œé–‰ TensorBoard ç´€éŒ„å™¨ï¼Œé‡‹æ”¾è³‡æº
        writer.close()
        torch.cuda.empty_cache()


# =======================
# Run pipeline
# =======================
if __name__ == "__main__":
    """
    --gpu_id -2ï¼šè‡ªå‹•é¸æ“‡æœ€ä½³GPU
    --gpu_id -1ï¼šå¼·åˆ¶ä½¿ç”¨CPU
    --gpu_id  0ï¼šä½¿ç”¨GPU 0ï¼ˆåŸæœ‰è¡Œç‚ºï¼‰
    """

    parser = argparse.ArgumentParser()
    parser.add_argument('--obj_id', action='store', type=int, required=True)
    parser.add_argument('--epochs', default=25, type=int)
    parser.add_argument('--bs', action='store', type=int, required=True)
    parser.add_argument('--lr', action='store', type=float, required=True)
    parser.add_argument('--gpu_id',
                        action='store',
                        type=int,
                        default=-2,
                        required=False,
                        help='GPU ID (-2: auto-select, -1: CPU)')
    args = parser.parse_args()

    # è‡ªå‹•é¸æ“‡GPU
    if args.gpu_id == -2:  # è‡ªå‹•é¸æ“‡æ¨¡å¼
        args.gpu_id = get_available_gpu()
        print(f"è‡ªå‹•é¸æ“‡ GPU: {args.gpu_id}")

    obj_batch = [['capsule'], ['bottle'], ['carpet'], ['leather'], ['pill'],
                 ['transistor'], ['tile'], ['cable'], ['zipper'],
                 ['toothbrush'], ['metal_nut'], ['hazelnut'], ['screw'],
                 ['grid'], ['wood']]

    if int(args.obj_id) == -1:
        obj_list = [
            'capsule', 'bottle', 'carpet', 'leather', 'pill', 'transistor',
            'tile', 'cable', 'zipper', 'toothbrush', 'metal_nut', 'hazelnut',
            'screw', 'grid', 'wood'
        ]
        picked_classes = obj_list
    else:
        picked_classes = obj_batch[int(args.obj_id)]

    # æ ¹æ“šé¸æ“‡çš„GPUåŸ·è¡Œ
    if args.gpu_id == -1:
        # ä½¿ç”¨CPU
        main(picked_classes, args)
    else:
        # ä½¿ç”¨GPU
        with torch.cuda.device(args.gpu_id):
            main(picked_classes, args)
